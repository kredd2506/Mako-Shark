{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Agentic Search Integration\n",
    "# %% [markdown]\n",
    "# This section adds documentation search capabilities with a crawl depth of 1\n",
    "# %%\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NRP_API_KEY\"] = \"NRP-API-key-here\"\n",
    "\n",
    "# %%\n",
    "import re\n",
    "\n",
    "\n",
    "# %%\n",
    "from kubernetes import client, config\n",
    "from kubernetes.client.exceptions import ApiException\n",
    "config.load_incluster_config()\n",
    "\n",
    "v1 = client.CoreV1Api()\n",
    "apps_v1 = client.AppsV1Api()\n",
    "batch_v1 = client.BatchV1Api()\n",
    "networking_v1 = client.NetworkingV1Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Implementing a simple react pattern\n",
    "\n",
    "# %%\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key = os.environ.get(\"NRP_API_KEY\"),\n",
    "    base_url = \"https://llm.nrp-nautilus.io/\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gemma3\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful Kubernetes assistant.\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Documentation Knowledge Base Class\n",
    "# %%\n",
    "class DocumentationKnowledgeBase:\n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.embeddings = None\n",
    "        self.metadata = []\n",
    "        self.api_key = os.environ.get(\"NRP_API_KEY\", \"NRP-API-key-here\")\n",
    "        self.base_url = \"https://llm.nrp-nautilus.io/\"\n",
    "        self.embedding_endpoint = f\"{self.base_url}/v1/embeddings\"\n",
    "        self.rerank_endpoint = f\"{self.base_url}/v1/rerank\"\n",
    "        \n",
    "        # Create a robust session with retries\n",
    "        self.session = requests.Session()\n",
    "        retry_strategy = Retry(\n",
    "            total=3,\n",
    "            backoff_factor=1,\n",
    "            status_forcelist=[429, 500, 502, 503, 504],\n",
    "            allowed_methods=[\"GET\", \"POST\"]\n",
    "        )\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        self.session.mount(\"http://\", adapter)\n",
    "        self.session.mount(\"https://\", adapter)\n",
    "        self.session.headers.update({\n",
    "            \"User-Agent\": \"NRP-Documentation-Crawler/1.0\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        })\n",
    "        \n",
    "    def crawl_documentation(self, base_url, max_depth=1, delay=2, timeout=30):\n",
    "        \"\"\"Crawl the NRP.ai documentation with specified depth\"\"\"\n",
    "        visited_urls = set()\n",
    "        pages_to_crawl = [(base_url, 0)]\n",
    "        failed_urls = []\n",
    "        \n",
    "        while pages_to_crawl:\n",
    "            url, depth = pages_to_crawl.pop(0)\n",
    "            \n",
    "            if depth > max_depth or url in visited_urls:\n",
    "                continue\n",
    "                \n",
    "            visited_urls.add(url)\n",
    "            time.sleep(delay)  # Delay between requests\n",
    "            \n",
    "            try:\n",
    "                print(f\"Crawling: {url} (depth: {depth})\")\n",
    "                response = self.session.get(url, timeout=timeout)\n",
    "                \n",
    "                if response.status_code != 200:\n",
    "                    print(f\"Failed to fetch {url}: Status {response.status_code}\")\n",
    "                    failed_urls.append(url)\n",
    "                    continue\n",
    "                    \n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                \n",
    "                # Extract page content\n",
    "                title = soup.find('title').get_text() if soup.find('title') else \"No Title\"\n",
    "                \n",
    "                # Try to find the main content area\n",
    "                content_div = soup.find('div', class_='documentation') or \\\n",
    "                              soup.find('main') or \\\n",
    "                              soup.find('article') or \\\n",
    "                              soup.find('div', class_='content') or \\\n",
    "                              soup\n",
    "                \n",
    "                content = content_div.get_text(strip=True)\n",
    "                \n",
    "                # Skip pages with very little content\n",
    "                if len(content) < 100:\n",
    "                    print(f\"Skipping {url} - insufficient content\")\n",
    "                    continue\n",
    "                \n",
    "                # Store document with metadata\n",
    "                self.documents.append({\n",
    "                    'text': content,\n",
    "                    'url': url,\n",
    "                    'title': title\n",
    "                })\n",
    "                \n",
    "                # Find all links\n",
    "                for link in soup.find_all('a', href=True):\n",
    "                    href = link['href']\n",
    "                    full_url = urljoin(url, href)\n",
    "                    \n",
    "                    # Only follow links within the documentation\n",
    "                    if urlparse(full_url).netloc == urlparse(base_url).netloc:\n",
    "                        pages_to_crawl.append((full_url, depth + 1))\n",
    "                        \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error crawling {url}: {e}\")\n",
    "                failed_urls.append(url)\n",
    "                continue\n",
    "                \n",
    "        print(f\"Crawled {len(self.documents)} pages\")\n",
    "        if failed_urls:\n",
    "            print(f\"Failed to crawl {len(failed_urls)} pages:\")\n",
    "            for url in failed_urls:\n",
    "                print(f\"  - {url}\")\n",
    "                \n",
    "    def get_embeddings(self, texts, batch_size=10):\n",
    "        \"\"\"Get embeddings from the NRP API with batching\"\"\"\n",
    "        all_embeddings = []\n",
    "        \n",
    "        # Process texts in batches to avoid overwhelming the API\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            data = {\n",
    "                \"model\": \"embed-mistral\",\n",
    "                \"input\": batch\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = self.session.post(self.embedding_endpoint, json=data, timeout=30)\n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()\n",
    "                    all_embeddings.extend([item['embedding'] for item in result['data']])\n",
    "                    print(f\"Processed batch {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}\")\n",
    "                else:\n",
    "                    print(f\"Error getting embeddings: {response.status_code} - {response.text}\")\n",
    "                    # Add zero embeddings as fallback\n",
    "                    all_embeddings.extend([[0.0] * 768] * len(batch))\n",
    "            except Exception as e:\n",
    "                print(f\"Exception when getting embeddings: {e}\")\n",
    "                # Add zero embeddings as fallback\n",
    "                all_embeddings.extend([[0.0] * 768] * len(batch))\n",
    "                \n",
    "            # Add delay between batches\n",
    "            time.sleep(1)\n",
    "            \n",
    "        return all_embeddings\n",
    "    \n",
    "    def rerank_results(self, query, documents, top_k=5):\n",
    "        \"\"\"Rerank search results using the NRP API\"\"\"\n",
    "        # Prepare documents for reranking\n",
    "        docs_for_rerank = [{\"text\": doc['text']} for doc in documents]\n",
    "        \n",
    "        data = {\n",
    "            \"model\": \"gemma3\",\n",
    "            \"query\": query,\n",
    "            \"documents\": docs_for_rerank,\n",
    "            \"top_n\": top_k\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = self.session.post(self.rerank_endpoint, json=data, timeout=30)\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                # Get indices of top results\n",
    "                top_indices = [item['index'] for item in result['results']]\n",
    "                return [documents[i] for i in top_indices]\n",
    "            else:\n",
    "                print(f\"Error reranking results: {response.status_code} - {response.text}\")\n",
    "                return documents[:top_k]  # Fallback to original order\n",
    "        except Exception as e:\n",
    "            print(f\"Exception when reranking: {e}\")\n",
    "            return documents[:top_k]  # Fallback to original order\n",
    "    \n",
    "    def search(self, query, top_k=5, use_reranking=True):\n",
    "        \"\"\"Search the knowledge base\"\"\"\n",
    "        if self.embeddings is None:\n",
    "            print(\"Knowledge base not loaded. Please load it first.\")\n",
    "            return []\n",
    "            \n",
    "        # Get query embedding\n",
    "        query_embedding = self.get_embeddings([query])\n",
    "        if query_embedding is None:\n",
    "            print(\"Failed to generate query embedding\")\n",
    "            return []\n",
    "            \n",
    "        query_embedding = np.array(query_embedding[0]).reshape(1, -1)\n",
    "        \n",
    "        # Calculate similarity\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings).flatten()\n",
    "        \n",
    "        # Get top results\n",
    "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "        \n",
    "        # Prepare results\n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'text': self.documents[idx]['text'],\n",
    "                'url': self.metadata[idx]['url'],\n",
    "                'title': self.metadata[idx]['title'],\n",
    "                'score': float(similarities[idx])\n",
    "            })\n",
    "        \n",
    "        # Apply reranking if requested\n",
    "        if use_reranking and len(results) > 0:\n",
    "            results = self.rerank_results(query, results, top_k)\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def build_knowledge_base(self):\n",
    "        \"\"\"Build the knowledge base with embeddings\"\"\"\n",
    "        if not self.documents:\n",
    "            print(\"No documents to process. Please crawl the documentation first.\")\n",
    "            return\n",
    "            \n",
    "        # Get embeddings for all documents\n",
    "        print(\"Generating embeddings...\")\n",
    "        texts = [doc['text'] for doc in self.documents]\n",
    "        embeddings = self.get_embeddings(texts)\n",
    "        \n",
    "        if embeddings is None:\n",
    "            print(\"Failed to generate embeddings\")\n",
    "            return\n",
    "            \n",
    "        self.embeddings = np.array(embeddings)\n",
    "        self.metadata = [{\n",
    "            'url': doc['url'],\n",
    "            'title': doc['title']\n",
    "        } for doc in self.documents]\n",
    "        \n",
    "        print(f\"Knowledge base built with {len(self.documents)} documents\")\n",
    "    \n",
    "    def save_knowledge_base(self, filepath):\n",
    "        \"\"\"Save the knowledge base to disk\"\"\"\n",
    "        if self.embeddings is None:\n",
    "            print(\"Knowledge base not built. Nothing to save.\")\n",
    "            return\n",
    "            \n",
    "        data = {\n",
    "            'documents': self.documents,\n",
    "            'embeddings': self.embeddings.tolist(),\n",
    "            'metadata': self.metadata\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "            \n",
    "        print(f\"Knowledge base saved to {filepath}\")\n",
    "    \n",
    "    def load_knowledge_base(self, filepath):\n",
    "        \"\"\"Load the knowledge base from disk\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        self.documents = data['documents']\n",
    "        self.embeddings = np.array(data['embeddings'])\n",
    "        self.metadata = data['metadata']\n",
    "        \n",
    "        print(f\"Knowledge base loaded from {filepath} with {len(self.documents)} documents\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Initialize Documentation Knowledge Base\n",
    "# %%\n",
    "# Initialize the knowledge base\n",
    "doc_kb = DocumentationKnowledgeBase()\n",
    "\n",
    "# Try to load the knowledge base from file\n",
    "kb_file = \"nrp_expert_docs_kb.json\"\n",
    "if os.path.exists(kb_file):\n",
    "    doc_kb.load_knowledge_base(kb_file)\n",
    "else:\n",
    "    print(f\"Knowledge base file {kb_file} not found. Building it now with crawl depth 1...\")\n",
    "    # Crawl the documentation with depth 1\n",
    "    doc_kb.crawl_documentation(\"https://nrp.ai/documentation/\", max_depth=1)\n",
    "    # Build the knowledge base\n",
    "    doc_kb.build_knowledge_base()\n",
    "    # Save for future use\n",
    "    doc_kb.save_knowledge_base(kb_file)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Documentation Search Function\n",
    "# %%\n",
    "def search_documentation(query):\n",
    "    \"\"\"\n",
    "    Search the NRP.ai documentation for the given query.\n",
    "    Returns a formatted string with the top results.\n",
    "    \"\"\"\n",
    "    if doc_kb.embeddings is None:\n",
    "        return \"❌ Knowledge base not loaded. Cannot search documentation.\"\n",
    "    \n",
    "    results = doc_kb.search(query, top_k=3)\n",
    "    if not results:\n",
    "        return \"❌ No relevant documentation found.\"\n",
    "    \n",
    "    output = []\n",
    "    for i, result in enumerate(results, 1):\n",
    "        output.append(f\"Result {i}:\")\n",
    "        output.append(f\"Title: {result['title']}\")\n",
    "        output.append(f\"URL: {result['url']}\")\n",
    "        output.append(f\"Content: {result['text'][:200]}...\")\n",
    "        output.append(\"\")  # Empty line\n",
    "    \n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Update Agent with Documentation Search\n",
    "# %%\n",
    "# Add the new action to known_actions\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Updated Agent Prompt\n",
    "# %%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=\"gemma3\", \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a Kubernetes assistant with access to NRP.ai documentation. You operate in a loop of:\n",
    "Thought → Action → PAUSE → Observation\n",
    "At the end of this loop, you output a final Answer.\n",
    "---\n",
    "**Instructions:**\n",
    "- Use **Thought** to explain your reasoning based on the user's request.\n",
    "- Use **Action** to call one of the tools listed below. Each Action must be followed by **PAUSE** so the system can run the tool.\n",
    "- The result of the action will be passed back to you as an **Observation**.\n",
    "- After processing the Observation, continue the loop.\n",
    "- Stop when you have gathered enough information, and provide an **Answer**.\n",
    "---\n",
    "**Namespace Rule:**\n",
    "- Always check if the namespace is set before performing any namespaced action.\n",
    "- If it is not set, ask: *\"Which namespace should I use?\"*\n",
    "- Then call: `set_namespace: <namespace>`\n",
    "---\n",
    "**When to Use `describe_*` Tools:**\n",
    "- If the user mentions a specific name (e.g., \"ubuntu\"), check for matching resources using `list_*` tools.\n",
    "- If a match is found, use the appropriate `describe_*` tool for detailed information.\n",
    "- If multiple resources match the name, describe each one.\n",
    "- Only use `describe_*` if you're confident about the target resource name.\n",
    "---\n",
    "**Documentation Search:**\n",
    "- When users ask about Kubernetes concepts, GPU pods, or cloud computing that isn't directly about cluster resources, use `search_documentation`.\n",
    "- This will search the NRP.ai documentation for relevant information.\n",
    "---\n",
    "**Available Actions:**\n",
    "set_namespace:\n",
    "e.g. set_namespace: kube-system\n",
    "Sets the namespace for all operations.\n",
    "list_pods:\n",
    "list_deployments:\n",
    "list_services:\n",
    "list_jobs:\n",
    "list_configmaps:\n",
    "list_secrets:\n",
    "list_pvcs:\n",
    "list_replicasets:\n",
    "list_statefulsets:\n",
    "list_daemonsets:\n",
    "list_events:\n",
    "list_ingresses:\n",
    "list_nodes:\n",
    "Each of the above lists the corresponding resources.\n",
    "describe_pod:\n",
    "describe_deployment:\n",
    "describe_job:\n",
    "describe_service:\n",
    "describe_configmap:\n",
    "describe_secret:\n",
    "describe_pvc:\n",
    "describe_replicaset:\n",
    "describe_statefulset:\n",
    "describe_daemonset:\n",
    "describe_ingress:\n",
    "describe_node:\n",
    "Each of the above describes the specified resource.\n",
    "search_documentation:\n",
    "e.g. search_documentation: How to set up GPU pods in Kubernetes?\n",
    "Searches the NRP.ai documentation for relevant information.\n",
    "---\n",
    "**Example 1:**\n",
    "Question: What pods are running?\n",
    "Thought: I need to check if the namespace is already set. Since it isn't, I will ask the user.\n",
    "Action: set_namespace: kube-system\n",
    "PAUSE\n",
    "(Observation: ✅ Namespace set to 'kube-system')\n",
    "Thought: Now I can list the pods in the kube-system namespace.\n",
    "Action: list_pods:\n",
    "PAUSE\n",
    "(Observation: ['coredns-abc123', 'kube-proxy-xyz789'])\n",
    "Answer: The pods currently running in kube-system are: coredns-abc123, kube-proxy-xyz789.\n",
    "---\n",
    "**Example 2:**\n",
    "Question: What is happening with ubuntu?\n",
    "Thought: The user asked about something named 'ubuntu'. I will first list pods to see if any match.\n",
    "Action: list_pods:\n",
    "PAUSE\n",
    "(Observation: ['ubuntu-runner-xyz', 'nginx'])\n",
    "Thought: A pod named 'ubuntu-runner-xyz' matches. I will describe it.\n",
    "Action: describe_pod: ubuntu-runner-xyz\n",
    "PAUSE\n",
    "(Observation: 📋 Pod 'ubuntu-runner-xyz' phase: Running, node: node-123)\n",
    "Answer: The pod 'ubuntu-runner-xyz' is currently running on node node-123.\n",
    "---\n",
    "**Example 3:**\n",
    "Question: How do I set up GPU pods in Kubernetes?\n",
    "Thought: The user is asking about setting up GPU pods. This is a configuration question that might be answered in the documentation. I will search the documentation.\n",
    "Action: search_documentation: How to set up GPU pods in Kubernetes?\n",
    "PAUSE\n",
    "(Observation: Result 1:\n",
    "Title: GPU Support in Kubernetes\n",
    "URL: https://nrp.ai/documentation/userdocs/gpu-support\n",
    "Content: Kubernetes provides support for GPUs through device plugins. To use GPUs in your pods...\n",
    ")\n",
    "Thought: The documentation search returned relevant information about GPU support in Kubernetes. I can now provide an answer based on this.\n",
    "Answer: According to the NRP.ai documentation, Kubernetes provides support for GPUs through device plugins. You can set up GPU pods by configuring your pods to request GPU resources. For detailed steps, see: https://nrp.ai/documentation/userdocs/gpu-support\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "CURRENT_NAMESPACE = None\n",
    "\n",
    "def set_namespace(ns):\n",
    "    \"\"\"\n",
    "    Set the global namespace for all Kubernetes operations.\n",
    "    \"\"\"\n",
    "    global CURRENT_NAMESPACE\n",
    "    CURRENT_NAMESPACE = ns.strip()\n",
    "    return f\"✅ Namespace set to '{CURRENT_NAMESPACE}'\"\n",
    "\n",
    "def get_namespace():\n",
    "    \"\"\"\n",
    "    Retrieve the currently set namespace.\n",
    "    Raises an error if namespace is not set.\n",
    "    \"\"\"\n",
    "    if CURRENT_NAMESPACE is None:\n",
    "        raise ValueError(\"❌ Namespace not set. Use `set_namespace` first.\")\n",
    "    return CURRENT_NAMESPACE\n",
    "\n",
    "\n",
    "# %%\n",
    "import re\n",
    "from kubernetes.client.rest import ApiException\n",
    "\n",
    "def validate_k8s_name(name):\n",
    "    \"\"\"\n",
    "    Validate that the name follows Kubernetes RFC1123 naming convention.\n",
    "    \"\"\"\n",
    "    pattern = r'^[a-z0-9]([-a-z0-9]*[a-z0-9])?$'\n",
    "    if not re.match(pattern, name):\n",
    "        raise ValueError(f\"❌ Invalid Kubernetes resource name: '{name}'. Must match RFC1123 format.\")\n",
    "    return name\n",
    "\n",
    "\n",
    "# ---------- LIST FUNCTIONS ----------\n",
    "\n",
    "def list_pods(_=None):\n",
    "    namespace = get_namespace()\n",
    "    pods = v1.list_namespaced_pod(namespace=namespace)\n",
    "    return [pod.metadata.name for pod in pods.items]\n",
    "\n",
    "def list_deployments(_=None):\n",
    "    namespace = get_namespace()\n",
    "    deployments = apps_v1.list_namespaced_deployment(namespace=namespace)\n",
    "    return [d.metadata.name for d in deployments.items]\n",
    "\n",
    "def list_services(_=None):\n",
    "    namespace = get_namespace()\n",
    "    services = v1.list_namespaced_service(namespace=namespace)\n",
    "    return [s.metadata.name for s in services.items]\n",
    "\n",
    "def list_jobs(_=None):\n",
    "    namespace = get_namespace()\n",
    "    jobs = batch_v1.list_namespaced_job(namespace=namespace)\n",
    "    return [j.metadata.name for j in jobs.items]\n",
    "\n",
    "def list_configmaps(_=None):\n",
    "    namespace = get_namespace()\n",
    "    cms = v1.list_namespaced_config_map(namespace=namespace)\n",
    "    return [cm.metadata.name for cm in cms.items]\n",
    "\n",
    "def list_secrets(_=None):\n",
    "    namespace = get_namespace()\n",
    "    secrets = v1.list_namespaced_secret(namespace=namespace)\n",
    "    return [s.metadata.name for s in secrets.items]\n",
    "\n",
    "def list_pvcs(_=None):\n",
    "    namespace = get_namespace()\n",
    "    pvcs = v1.list_namespaced_persistent_volume_claim(namespace=namespace)\n",
    "    return [p.metadata.name for p in pvcs.items]\n",
    "\n",
    "def list_replicasets(_=None):\n",
    "    namespace = get_namespace()\n",
    "    rsets = apps_v1.list_namespaced_replica_set(namespace=namespace)\n",
    "    return [r.metadata.name for r in rsets.items]\n",
    "\n",
    "def list_statefulsets(_=None):\n",
    "    namespace = get_namespace()\n",
    "    ssets = apps_v1.list_namespaced_stateful_set(namespace=namespace)\n",
    "    return [s.metadata.name for s in ssets.items]\n",
    "\n",
    "def list_daemonsets(_=None):\n",
    "    namespace = get_namespace()\n",
    "    dsets = apps_v1.list_namespaced_daemon_set(namespace=namespace)\n",
    "    return [d.metadata.name for d in dsets.items]\n",
    "\n",
    "def list_ingresses(_=None):\n",
    "    namespace = get_namespace()\n",
    "    ingresses = networking_v1.list_namespaced_ingress(namespace=namespace)\n",
    "    return [i.metadata.name for i in ingresses.items]\n",
    "\n",
    "def list_events(_=None):\n",
    "    namespace = get_namespace()\n",
    "    events = v1.list_namespaced_event(namespace=namespace)\n",
    "    return [f\"{e.last_timestamp}: {e.message}\" for e in events.items]\n",
    "\n",
    "def list_nodes(_=None):\n",
    "    nodes = v1.list_node()\n",
    "    return [n.metadata.name for n in nodes.items]\n",
    "\n",
    "\n",
    "# ---------- DESCRIBE FUNCTIONS ----------\n",
    "\n",
    "def describe_pod(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        pod = v1.read_namespaced_pod(name=name, namespace=namespace)\n",
    "        return f\"📋 Pod '{name}' phase: {pod.status.phase}, node: {pod.spec.node_name}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ Pod '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise  # Re-raise other exceptions\n",
    "\n",
    "def describe_deployment(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        dep = apps_v1.read_namespaced_deployment(name=name, namespace=namespace)\n",
    "        return f\"📦 Deployment '{name}' has {dep.status.replicas or 0} replicas and {dep.status.ready_replicas or 0} ready.\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ Deployment '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_service(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        svc = v1.read_namespaced_service(name=name, namespace=namespace)\n",
    "        return f\"🌐 Service '{name}' type: {svc.spec.type}, cluster IP: {svc.spec.cluster_ip}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ Service '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_job(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        job = batch_v1.read_namespaced_job(name=name, namespace=namespace)\n",
    "        return f\"⚙️ Job '{name}' completions: {job.status.succeeded or 0}, active: {job.status.active or 0}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ Job '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_configmap(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        cm = v1.read_namespaced_config_map(name=name, namespace=namespace)\n",
    "        keys = list(cm.data.keys()) if cm.data else []\n",
    "        return f\"🗂️ ConfigMap '{name}' has keys: {keys}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ ConfigMap '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_secret(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        sec = v1.read_namespaced_secret(name=name, namespace=namespace)\n",
    "        keys = list(sec.data.keys()) if sec.data else []\n",
    "        return f\"🔒 Secret '{name}' contains {len(keys)} keys (values hidden)\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ Secret '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_pvc(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        pvc = v1.read_namespaced_persistent_volume_claim(name=name, namespace=namespace)\n",
    "        return f\"💾 PVC '{name}' status: {pvc.status.phase}, capacity: {pvc.status.capacity.get('storage')}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ PVC '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_replicaset(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        rs = apps_v1.read_namespaced_replica_set(name=name, namespace=namespace)\n",
    "        return f\"📎 ReplicaSet '{name}' replicas: {rs.status.replicas}, ready: {rs.status.ready_replicas}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ ReplicaSet '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_statefulset(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        ss = apps_v1.read_namespaced_stateful_set(name=name, namespace=namespace)\n",
    "        return f\"📘 StatefulSet '{name}' replicas: {ss.status.replicas}, ready: {ss.status.ready_replicas}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ StatefulSet '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_daemonset(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        ds = apps_v1.read_namespaced_daemon_set(name=name, namespace=namespace)\n",
    "        return f\"🔁 DaemonSet '{name}' scheduled: {ds.status.current_number_scheduled}, ready: {ds.status.number_ready}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ DaemonSet '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_ingress(name):\n",
    "    name = name.strip()\n",
    "    namespace = get_namespace()\n",
    "    try:\n",
    "        ing = networking_v1.read_namespaced_ingress(name=name, namespace=namespace)\n",
    "        hosts = [rule.host for rule in ing.spec.rules] if ing.spec.rules else []\n",
    "        services = []\n",
    "        for rule in ing.spec.rules or []:\n",
    "            if rule.http:\n",
    "                for path in rule.http.paths:\n",
    "                    if path.backend and path.backend.service:\n",
    "                        services.append(path.backend.service.name)\n",
    "        return f\"🚪 Ingress '{name}' exposes hosts: {hosts or '[]'} and forwards to services: {services or '[]'}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ Ingress '{name}' not found in namespace '{namespace}'.\"\n",
    "        raise\n",
    "\n",
    "def describe_node(name):\n",
    "    name = name.strip()\n",
    "    try:\n",
    "        node = v1.read_node(name=name)\n",
    "        return f\"🖥️ Node '{name}' labels: {node.metadata.labels}\"\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            return f\"❌ Node '{name}' not found.\"\n",
    "        raise\n",
    "\n",
    "\n",
    "# %%\n",
    "known_actions = {\n",
    "    # Namespace control\n",
    "    \"set_namespace\": set_namespace,\n",
    "\n",
    "    # LIST actions\n",
    "    \"list_pods\": list_pods,\n",
    "    \"list_deployments\": list_deployments,\n",
    "    \"list_services\": list_services,\n",
    "    \"list_jobs\": list_jobs,\n",
    "    \"list_configmaps\": list_configmaps,\n",
    "    \"list_secrets\": list_secrets,\n",
    "    \"list_pvcs\": list_pvcs,\n",
    "    \"list_replicasets\": list_replicasets,\n",
    "    \"list_statefulsets\": list_statefulsets,\n",
    "    \"list_daemonsets\": list_daemonsets,\n",
    "    \"list_ingresses\": list_ingresses,\n",
    "    \"list_events\": list_events,\n",
    "    \"list_nodes\": list_nodes,\n",
    "\n",
    "    # DESCRIBE actions\n",
    "    \"describe_pod\": describe_pod,\n",
    "    \"describe_deployment\": describe_deployment,\n",
    "    \"describe_service\": describe_service,\n",
    "    \"describe_job\": describe_job,\n",
    "    \"describe_configmap\": describe_configmap,\n",
    "    \"describe_secret\": describe_secret,\n",
    "    \"describe_pvc\": describe_pvc,\n",
    "    \"describe_replicaset\": describe_replicaset,\n",
    "    \"describe_statefulset\": describe_statefulset,\n",
    "    \"describe_daemonset\": describe_daemonset,\n",
    "    \"describe_ingress\": describe_ingress,\n",
    "    \"describe_node\": describe_node,\n",
    "\n",
    "\n",
    "    \"search_documentation\": search_documentation,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Add Loop\n",
    "\n",
    "# %%\n",
    "action_re = re.compile(r'^Action: (\\w+):(.*)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def query(question, max_turns=15):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        print(f\"\\n--- Turn {i+1} ---\")\n",
    "        i += 1\n",
    "        print(\"Prompt to bot:\", next_prompt)\n",
    "\n",
    "        result = bot(next_prompt)\n",
    "        print(\"Bot response:\\n\", result)\n",
    "\n",
    "        actions = [\n",
    "            action_re.match(a)\n",
    "            for a in result.split('\\n')\n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "\n",
    "        if actions:\n",
    "            for action_match in actions:\n",
    "                action, action_input = action_match.groups()\n",
    "                if action not in known_actions:\n",
    "                    raise Exception(f\"Unknown action: {action}: {action_input}\")\n",
    "                print(f\" -- Running action '{action}' with input '{action_input}'\")\n",
    "                observation = known_actions[action](action_input)\n",
    "                print(\"Observation:\", observation)\n",
    "                next_prompt = f\"Observation: {observation}\"\n",
    "        else:\n",
    "            print(\"No more actions. Halting.\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Test Documentation Search\n",
    "# %%\n",
    "# Create a new agent with the updated prompt\n",
    "abot = Agent(prompt)\n",
    "\n",
    "# Test the documentation search\n",
    "question = \"How do I configure persistent storage in Kubernetes?\"\n",
    "result = abot(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"How do I configure persistent storage in Kubernetes?\"\"\"\n",
    "\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "question = \"\"\"I want to everything related to the name ubuntu in gsoc namespace and explain them\"\"\"\n",
    "\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "question = \"\"\"How can I provision an FPGA?\"\"\"\n",
    "\n",
    "query(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
