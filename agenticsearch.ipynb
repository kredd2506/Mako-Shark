{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Agentic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Manual sitemap parsing (bypassing the XML parser issue)\n",
    "\n",
    "import requests\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import xml.etree.ElementTree as ET\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "import requests\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def load_kubernetes_docs():\n",
    "    \"\"\"Load Kubernetes documentation by manually parsing the sitemap\"\"\"\n",
    "    \n",
    "    sitemap_url = \"https://kubernetes.io/en/sitemap.xml\"\n",
    "    filter_prefix = \"https://kubernetes.io/docs/\"\n",
    "    \n",
    "    print(\"Fetching sitemap...\")\n",
    "    try:\n",
    "        # Get the sitemap\n",
    "        response = requests.get(sitemap_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse XML using built-in ElementTree (no external dependencies)\n",
    "        root = ET.fromstring(response.content)\n",
    "        \n",
    "        # Extract URLs from sitemap\n",
    "        urls = []\n",
    "        namespace = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "        \n",
    "        for url_elem in root.findall('.//ns:url', namespace):\n",
    "            loc_elem = url_elem.find('ns:loc', namespace)\n",
    "            if loc_elem is not None:\n",
    "                url_text = loc_elem.text\n",
    "                if url_text and url_text.startswith(filter_prefix):\n",
    "                    urls.append(url_text)\n",
    "        \n",
    "        print(f\"Found {len(urls)} Kubernetes documentation URLs\")\n",
    "        \n",
    "        # Load documents (start with a small batch for testing)\n",
    "        docs = []\n",
    "        max_docs = min(50, len(urls))  # Limit to 50 docs for initial testing\n",
    "        \n",
    "        for i, url in enumerate(urls[:max_docs]):\n",
    "            try:\n",
    "                print(f\"Loading {i+1}/{max_docs}: {url}\")\n",
    "                loader = WebBaseLoader(url)\n",
    "                doc_list = loader.load()\n",
    "                if doc_list:\n",
    "                    docs.extend(doc_list)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Failed to load {url}: {str(e)[:100]}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nSuccessfully loaded {len(docs)} documents\")\n",
    "        return docs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching sitemap: {e}\")\n",
    "        return []\n",
    "\n",
    "# ALTERNATIVE: Direct URL approach if sitemap still doesn't work\n",
    "def load_kubernetes_docs_direct():\n",
    "    \"\"\"Load specific Kubernetes documentation pages directly\"\"\"\n",
    "    \n",
    "    # Key Kubernetes documentation URLs to start with\n",
    "    key_urls = [\n",
    "        \"https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/\",\n",
    "        \"https://kubernetes.io/docs/concepts/workloads/pods/\",\n",
    "        \"https://kubernetes.io/docs/concepts/services-networking/service/\",\n",
    "        \"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/\",\n",
    "        \"https://kubernetes.io/docs/concepts/configuration/configmap/\",\n",
    "        \"https://kubernetes.io/docs/concepts/configuration/secret/\",\n",
    "        \"https://kubernetes.io/docs/concepts/services-networking/ingress/\",\n",
    "        \"https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/\",\n",
    "        \"https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/\",\n",
    "        \"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/\",\n",
    "        \"https://kubernetes.io/docs/concepts/storage/volumes/\",\n",
    "        \"https://kubernetes.io/docs/concepts/storage/persistent-volumes/\",\n",
    "        \"https://kubernetes.io/docs/concepts/cluster-administration/namespaces/\",\n",
    "        \"https://kubernetes.io/docs/reference/kubectl/cheatsheet/\",\n",
    "        \"https://kubernetes.io/docs/tasks/manage-kubernetes-objects/declarative-config/\",\n",
    "        \"https://kubernetes.io/docs/tutorials/kubernetes-basics/\",\n",
    "        \"https://kubernetes.io/docs/concepts/security/rbac/\",\n",
    "        \"https://kubernetes.io/docs/concepts/policy/resource-quotas/\",\n",
    "        \"https://kubernetes.io/docs/concepts/policy/limit-ranges/\",\n",
    "        \"https://kubernetes.io/docs/concepts/cluster-administration/networking/\"\n",
    "    ]\n",
    "    \n",
    "    docs = []\n",
    "    print(f\"Loading {len(key_urls)} key Kubernetes documentation pages...\")\n",
    "    \n",
    "    for i, url in enumerate(key_urls):\n",
    "        try:\n",
    "            print(f\"Loading {i+1}/{len(key_urls)}: {url.split('/')[-2]}\")\n",
    "            loader = WebBaseLoader(url)\n",
    "            doc_list = loader.load()\n",
    "            if doc_list:\n",
    "                docs.extend(doc_list)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Failed to load {url}: {str(e)[:100]}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Successfully loaded {len(docs)} key documentation pages\")\n",
    "    return docs\n",
    "\n",
    "# Try the sitemap approach first, fall back to direct URLs\n",
    "print(\"Attempting to load from sitemap...\")\n",
    "docs = load_kubernetes_docs()\n",
    "\n",
    "if len(docs) == 0:\n",
    "    print(\"\\nSitemap approach failed, using direct URL approach...\")\n",
    "    docs = load_kubernetes_docs_direct()\n",
    "\n",
    "# Now continue with your text splitting and processing\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "print(\"Splitting documents into chunks...\")\n",
    "texts = text_splitter.split_documents(docs)\n",
    "print(f\"Created {len(texts)} text chunks\")\n",
    "\n",
    "# Continue with your embedding and vector store setup..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Using NRP-hosted embed-mistral for FAISS vector store\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Set OpenAI-compatible NRP API details\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"API-key-here\"\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://llm.nrp-nautilus.io/v1\"\n",
    "\n",
    "# Step 1: Sanity test call to NRP embedding endpoint\n",
    "print(\"üìå Testing 'embed-mistral' model from NRP...\")\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    base_url=os.environ[\"OPENAI_BASE_URL\"]\n",
    ")\n",
    "\n",
    "try:\n",
    "    test = client.embeddings.create(\n",
    "        model=\"embed-mistral\",\n",
    "        input=[\"test embedding\"]\n",
    "    )\n",
    "    print(\"‚úÖ Embedding test successful. Response shape:\", len(test.data[0].embedding))\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Embedding model 'embed-mistral' failed:\", e)\n",
    "    raise e\n",
    "\n",
    "# Step 2: Initialize LangChain OpenAI-compatible embeddings\n",
    "print(\"üîç Creating embeddings using NRP 'embed-mistral'...\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"embed-mistral\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    base_url=os.environ[\"OPENAI_BASE_URL\"]\n",
    ")\n",
    "\n",
    "# Step 3: Ensure input is a list of plain strings\n",
    "texts = [doc.page_content for doc in texts]  # assumes `texts` is List[Document]\n",
    "\n",
    "# Step 4: Build FAISS vector store\n",
    "print(\"üì¶ Building vector store...\")\n",
    "vectorstore = FAISS.from_texts(texts=texts, embedding=embeddings)\n",
    "\n",
    "# Step 5: Save vector store\n",
    "vectorstore.save_local(\"kubernetes_vectorstore\")\n",
    "print(\"‚úÖ Vector store saved locally.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Set up the Agentic Retrieval System\n",
    "print(\"\\nSetting up retrieval system...\")\n",
    "\n",
    "# Create retriever with multiple search strategies\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",  # Maximum Marginal Relevance for diverse results\n",
    "    search_kwargs={\n",
    "        \"k\": 8,  # Retrieve top 8 most relevant chunks\n",
    "        \"fetch_k\": 20,  # Fetch 20 candidates before MMR selection\n",
    "        \"lambda_mult\": 0.7  # Diversity vs relevance balance\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    temperature=0.1,  # Low temperature for factual responses\n",
    "    max_tokens=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4: Create Agentic Search Template\n",
    "agentic_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a Kubernetes expert assistant with access to official documentation. \n",
    "Your goal is to provide accurate, helpful answers about Kubernetes concepts, troubleshooting, and best practices.\n",
    "\n",
    "Context from Kubernetes documentation:\n",
    "{context}\n",
    "\n",
    "Human question: {question}\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the question to understand what the user needs\n",
    "2. Use the provided context to give accurate information\n",
    "3. If the context doesn't fully answer the question, clearly state what information is missing\n",
    "4. Provide practical examples when relevant\n",
    "5. Suggest follow-up questions or related topics that might be helpful\n",
    "6. If you detect the user might need step-by-step guidance, offer to break down complex tasks\n",
    "\n",
    "Answer:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Create the QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": agentic_prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"Agentic search system ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Test the Agentic Search System\n",
    "def agentic_search(question, show_sources=True):\n",
    "    \"\"\"\n",
    "    Perform agentic search on Kubernetes documentation\n",
    "    \"\"\"\n",
    "    print(f\"üîç Searching for: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get answer and sources\n",
    "    result = qa_chain({\"query\": question})\n",
    "    \n",
    "    print(\"üìã Answer:\")\n",
    "    print(result[\"result\"])\n",
    "    \n",
    "    if show_sources and result.get(\"source_documents\"):\n",
    "        print(\"\\nüìö Sources:\")\n",
    "        for i, doc in enumerate(result[\"source_documents\"][:3], 1):\n",
    "            source_url = doc.metadata.get(\"source\", \"Unknown\")\n",
    "            print(f\"{i}. {source_url}\")\n",
    "            print(f\"   Preview: {doc.page_content[:200]}...\")\n",
    "            print()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test with sample questions\n",
    "test_questions = [\n",
    "    \"What is a Pod in Kubernetes and how does it work?\",\n",
    "    \"How do I troubleshoot a failing deployment?\",\n",
    "    \"What's the difference between Services and Ingress?\",\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing the agentic search system:\")\n",
    "for question in test_questions[:1]:  # Test with first question\n",
    "    result = agentic_search(question)\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Advanced Agentic Features\n",
    "class KubernetesAgent:\n",
    "    def __init__(self, qa_chain):\n",
    "        self.qa_chain = qa_chain\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def search_with_context(self, question):\n",
    "        \"\"\"Search with conversation context\"\"\"\n",
    "        \n",
    "        # Add conversation context to question if available\n",
    "        if self.conversation_history:\n",
    "            context_question = f\"\"\"\n",
    "            Previous conversation context:\n",
    "            {' '.join(self.conversation_history[-3:])}\n",
    "            \n",
    "            Current question: {question}\n",
    "            \"\"\"\n",
    "        else:\n",
    "            context_question = question\n",
    "        \n",
    "        result = self.qa_chain({\"query\": context_question})\n",
    "        \n",
    "        # Store in conversation history\n",
    "        self.conversation_history.append(f\"Q: {question}\")\n",
    "        self.conversation_history.append(f\"A: {result['result'][:200]}...\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def suggest_follow_ups(self, question, answer):\n",
    "        \"\"\"Generate follow-up questions based on the current Q&A\"\"\"\n",
    "        \n",
    "        follow_up_prompt = f\"\"\"\n",
    "        Based on this Kubernetes Q&A:\n",
    "        Q: {question}\n",
    "        A: {answer[:300]}...\n",
    "        \n",
    "        Suggest 3 relevant follow-up questions a user might ask.\n",
    "        Return only the questions, one per line.\n",
    "        \"\"\"\n",
    "        \n",
    "        follow_up_result = self.qa_chain.llm.invoke(follow_up_prompt)\n",
    "        return follow_up_result.content.strip().split('\\n')\n",
    "    \n",
    "    def interactive_search(self):\n",
    "        \"\"\"Interactive search session\"\"\"\n",
    "        print(\"ü§ñ Kubernetes Agent activated! Ask me anything about Kubernetes.\")\n",
    "        print(\"Type 'quit' to exit, 'clear' to clear history\")\n",
    "        \n",
    "        while True:\n",
    "            question = input(\"\\n‚ùì Your question: \").strip()\n",
    "            \n",
    "            if question.lower() == 'quit':\n",
    "                break\n",
    "            elif question.lower() == 'clear':\n",
    "                self.conversation_history = []\n",
    "                print(\"üìù Conversation history cleared!\")\n",
    "                continue\n",
    "            elif not question:\n",
    "                continue\n",
    "            \n",
    "            # Get answer\n",
    "            result = self.search_with_context(question)\n",
    "            print(f\"\\nü§ñ Answer: {result['result']}\")\n",
    "            \n",
    "            # Show sources\n",
    "            if result.get(\"source_documents\"):\n",
    "                print(f\"\\nüìö Key sources: {len(result['source_documents'])} documents referenced\")\n",
    "            \n",
    "            # Suggest follow-ups\n",
    "            follow_ups = self.suggest_follow_ups(question, result['result'])\n",
    "            print(\"\\nüí° You might also want to ask:\")\n",
    "            for i, follow_up in enumerate(follow_ups[:3], 1):\n",
    "                if follow_up.strip():\n",
    "                    print(f\"   {i}. {follow_up.strip()}\")\n",
    "\n",
    "# Initialize the agent\n",
    "k8s_agent = KubernetesAgent(qa_chain)\n",
    "\n",
    "print(\"üöÄ Kubernetes Agentic Search System Ready!\")\n",
    "print(\"\\nTry these commands:\")\n",
    "print(\"- agentic_search('your question here')\")\n",
    "print(\"- k8s_agent.interactive_search()  # For interactive session\")\n",
    "print(\"- k8s_agent.search_with_context('your question')  # With conversation memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-community langchain-openai faiss-cpu sentence-transformers requests beautifulsoup4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
