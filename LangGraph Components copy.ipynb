{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "LangGraph Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kubernetes import client, config\n",
    "from kubernetes.client.exceptions import ApiException\n",
    "\n",
    "os.environ[\"NRP_API_KEY\"] = \"Api key here\"\n",
    "config.load_incluster_config()\n",
    "\n",
    "v1 = client.CoreV1Api()\n",
    "apps_v1 = client.AppsV1Api()\n",
    "batch_v1 = client.BatchV1Api()\n",
    "networking_v1 = client.NetworkingV1Api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"NRP_API_KEY\"),\n",
    "    base_url=\"https://llm.nrp-nautilus.io/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_pods(namespace=\"gsoc\"):\n",
    "    \"\"\"\n",
    "    Describe pods and print only fields useful for Prometheus metric queries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pods = v1.list_namespaced_pod(namespace=namespace) if namespace else v1.list_pod_for_all_namespaces()\n",
    "\n",
    "        rows = []\n",
    "        for pod in pods.items:\n",
    "            pod_name = pod.metadata.name\n",
    "            ns = pod.metadata.namespace\n",
    "            pod_ip = pod.status.pod_ip\n",
    "            node = pod.spec.node_name\n",
    "            container_names = [c.name for c in pod.spec.containers]\n",
    "            container = \", \".join(container_names)\n",
    "\n",
    "            rows.append([pod_name, ns, pod_ip, node, container])\n",
    "\n",
    "        headers = [\"Pod\", \"Namespace\", \"Pod IP\", \"Node\", \"Container\"]\n",
    "        print(tabulate(rows, headers=headers, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    except ApiException as e:\n",
    "        print(f\"‚ùå Error fetching pods: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_pods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#namespace gpu utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def namespace_gpu_utilization(prom_url=\"https://prometheus.nrp-nautilus.io\", threshold=0):\n",
    "    \"\"\"\n",
    "    Display average GPU utilization per namespace using PromQL.\n",
    "    Args:\n",
    "        prom_url (str): Base Prometheus URL.\n",
    "        threshold (float): Minimum % utilization to show (filtering).\n",
    "    \"\"\"\n",
    "    query = 'avg by (namespace) (DCGM_FI_DEV_GPU_UTIL)'\n",
    "    url = f\"{prom_url}/api/v1/query\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params={\"query\": query}, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if data.get(\"status\") != \"success\":\n",
    "            print(\"‚ùå Prometheus query failed.\")\n",
    "            return\n",
    "\n",
    "        results = data[\"data\"][\"result\"]\n",
    "        if not results:\n",
    "            print(\"‚úÖ Query successful, but no GPU usage data returned.\")\n",
    "            return\n",
    "\n",
    "        rows = []\n",
    "        for r in results:\n",
    "            ns = r[\"metric\"].get(\"namespace\", \"unknown\")\n",
    "            util = float(r[\"value\"][1])\n",
    "            if util >= threshold:\n",
    "                status = (\n",
    "                    \"üü¢ Low\" if util < 40 else\n",
    "                    \"üü° Moderate\" if util < 70 else\n",
    "                    \"üî¥ High\"\n",
    "                )\n",
    "                rows.append([ns, f\"{util:.2f}%\", status])\n",
    "\n",
    "        headers = [\"Namespace\", \"Avg GPU Utilization\", \"Status\"]\n",
    "        print(tabulate(rows, headers=headers, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error querying Prometheus: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tabulate import tabulate\n",
    "\n",
    "def fetch_dcgm_gpu_util_data(prom_url=\"https://prometheus.nrp-nautilus.io\"):\n",
    "    \"\"\"\n",
    "    Fetch rich GPU utilization data from Prometheus using DCGM_FI_DEV_GPU_UTIL.\n",
    "    \n",
    "    Returns:\n",
    "        list of dicts with context: [{hostname, gpu_id, model, namespace, pod, utilization, ...}]\n",
    "    \"\"\"\n",
    "    query = 'DCGM_FI_DEV_GPU_UTIL'\n",
    "    url = f\"{prom_url}/api/v1/query\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params={\"query\": query}, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if data.get(\"status\") != \"success\":\n",
    "            print(\"‚ùå Prometheus query failed.\")\n",
    "            return []\n",
    "\n",
    "        results = data[\"data\"][\"result\"]\n",
    "        if not results:\n",
    "            print(\"‚úÖ Query successful, but no GPU data returned.\")\n",
    "            return []\n",
    "\n",
    "        enriched = []\n",
    "        for r in results:\n",
    "            m = r[\"metric\"]\n",
    "            val = float(r[\"value\"][1])\n",
    "            enriched.append({\n",
    "                \"hostname\": m.get(\"Hostname\", \"unknown\"),\n",
    "                \"ip_port\": m.get(\"instance\", \"unknown\"),\n",
    "                \"gpu_id\": m.get(\"gpu\", \"N/A\"),\n",
    "                \"device\": m.get(\"device\", \"N/A\"),\n",
    "                \"uuid\": m.get(\"UUID\", \"N/A\"),\n",
    "                \"model\": m.get(\"modelName\", \"unknown\"),\n",
    "                \"namespace\": m.get(\"namespace\", \"N/A\"),\n",
    "                \"pod\": m.get(\"pod\", \"N/A\"),\n",
    "                \"utilization\": val\n",
    "            })\n",
    "\n",
    "        return enriched\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error querying Prometheus: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def display_gpu_data_head(data, n=5):\n",
    "    \"\"\"\n",
    "    Display the first `n` GPU entries with rich context.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to display.\")\n",
    "        return\n",
    "\n",
    "    rows = [\n",
    "        [d[\"hostname\"], d[\"gpu_id\"], d[\"model\"], f\"{d['utilization']:.2f}%\", d[\"namespace\"], d[\"pod\"]]\n",
    "        for d in data[:n]\n",
    "    ]\n",
    "    print(tabulate(rows, headers=[\"Host\", \"GPU\", \"Model\", \"Utilization\", \"Namespace\", \"Pod\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "\n",
    "def analyze_dcgm_gpu_data(data):\n",
    "    \"\"\"\n",
    "    Analyze DCGM GPU data with statistics and top utilization.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to analyze.\")\n",
    "        return\n",
    "\n",
    "    total = len(data)\n",
    "    avg_util = sum(d[\"utilization\"] for d in data) / total\n",
    "    maxed = [d for d in data if d[\"utilization\"] >= 99.0]\n",
    "    idle = [d for d in data if d[\"utilization\"] < 1.0]\n",
    "    available = [d for d in data if d[\"utilization\"] < 100.0]\n",
    "    unique_hosts = set(d[\"hostname\"] for d in data)\n",
    "    unique_models = set(d[\"model\"] for d in data)\n",
    "\n",
    "    print(f\"\\nüîç Total GPUs: {total}\")\n",
    "    print(f\"üìä Average Utilization: {avg_util:.2f}%\")\n",
    "    print(f\"üî¥ Fully Utilized GPUs (>=99%): {len(maxed)}\")\n",
    "    print(f\"üü¢ Idle GPUs (<1%): {len(idle)}\")\n",
    "    print(f\"üíª Unique Host Machines: {len(unique_hosts)}\")\n",
    "    print(f\"üß† Unique GPU Models: {len(unique_models)}\")\n",
    "    print(f\"üßÆ GPUs Available (<100%): {len(available)}\\n\")\n",
    "\n",
    "    print(\"üìà Top 10 GPUs by Utilization:\")\n",
    "    top = sorted(data, key=lambda x: x[\"utilization\"], reverse=True)[:10]\n",
    "    rows = [[d[\"hostname\"], d[\"gpu_id\"], d[\"model\"], f\"{d['utilization']:.2f}%\", d[\"namespace\"], d[\"pod\"]] for d in top]\n",
    "    print(tabulate(rows, headers=[\"Host\", \"GPU\", \"Model\", \"Utilization\", \"Namespace\", \"Pod\"], tablefmt=\"github\"))\n",
    "\n",
    "\n",
    "# Run it\n",
    "if __name__ == \"__main__\":\n",
    "    data = fetch_dcgm_gpu_util_data()\n",
    "    display_gpu_data_head(data, n=5)\n",
    "    analyze_dcgm_gpu_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from typing import Optional\n",
    "from io import StringIO\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Helper to capture and truncate printed output\n",
    "def capture_stdout_truncated(func, max_length=2000, *args, **kwargs):\n",
    "    \"\"\"Capture stdout and truncate if too long to prevent LLM loops\"\"\"\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    try:\n",
    "        func(*args, **kwargs)\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "    \n",
    "    output = mystdout.getvalue()\n",
    "    if len(output) > max_length:\n",
    "        output = output[:max_length] + f\"\\n\\n... [Output truncated - showing first {max_length} characters]\"\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools with truncated outputs\n",
    "@tool\n",
    "def describe_pods_tool(namespace: Optional[str] = \"gsoc\") -> str:\n",
    "    \"\"\"Describe pods in a given Kubernetes namespace. Defaults to 'gsoc'.\"\"\"\n",
    "    return capture_stdout_truncated(describe_pods, 1500, namespace=namespace)\n",
    "\n",
    "@tool\n",
    "def namespace_gpu_util_tool(threshold: Optional[float] = 0.0) -> str:\n",
    "    \"\"\"Get average GPU utilization per namespace with optional threshold filter.\"\"\"\n",
    "    return capture_stdout_truncated(namespace_gpu_utilization, 1500, threshold=threshold)\n",
    "\n",
    "@tool\n",
    "def dcgm_gpu_inspect_tool(threshold: float = 0.0) -> str:\n",
    "    \"\"\"\n",
    "    Inspect raw GPU usage with model name, host, pod, and utilization.\n",
    "    Shows top 10 GPUs above threshold to prevent overwhelming output.\n",
    "    \"\"\"\n",
    "    data = fetch_dcgm_gpu_util_data()\n",
    "    if not data:\n",
    "        return \"‚ö†Ô∏è No GPU data available.\"\n",
    "\n",
    "    filtered = [d for d in data if d[\"utilization\"] >= threshold]\n",
    "    if not filtered:\n",
    "        return f\"‚úÖ No GPUs over {threshold}% utilization.\"\n",
    "\n",
    "    # Limit to top 10 to prevent massive output\n",
    "    top = sorted(filtered, key=lambda x: x[\"utilization\"], reverse=True)[:10]\n",
    "    rows = [\n",
    "        [d[\"hostname\"][:20], d[\"gpu_id\"], d[\"model\"][:25], f\"{d['utilization']:.2f}%\", d[\"namespace\"], d[\"pod\"][:20]]\n",
    "        for d in top\n",
    "    ]\n",
    "    \n",
    "    from tabulate import tabulate\n",
    "    result = tabulate(rows, headers=[\"Host\", \"GPU\", \"Model\", \"Util%\", \"Namespace\", \"Pod\"], tablefmt=\"grid\")\n",
    "    \n",
    "    # Add summary info\n",
    "    result += f\"\\n\\nShowing top 10 of {len(filtered)} GPUs above {threshold}% threshold.\"\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def calculate_dcgm_gpu_stats(threshold: float = 0.0) -> str:\n",
    "    \"\"\"\n",
    "    Analyze GPU utilization across nodes and return statistical breakdown.\n",
    "    Includes averages, idle/overloaded counts, and model/host distribution.\n",
    "    \"\"\"\n",
    "    data = fetch_dcgm_gpu_util_data()\n",
    "    if not data:\n",
    "        return \"‚ö†Ô∏è No GPU data available.\"\n",
    "\n",
    "    filtered = [d for d in data if d[\"utilization\"] >= threshold]\n",
    "    total = len(filtered)\n",
    "    if total == 0:\n",
    "        return f\"‚úÖ No GPUs over the threshold of {threshold}% utilization.\"\n",
    "\n",
    "    avg_util = sum(d[\"utilization\"] for d in filtered) / total\n",
    "    maxed = [d for d in filtered if d[\"utilization\"] >= 99.0]\n",
    "    idle = [d for d in filtered if d[\"utilization\"] < 1.0]\n",
    "    moderate = [d for d in filtered if 1.0 <= d[\"utilization\"] < 70.0]\n",
    "    available = [d for d in filtered if d[\"utilization\"] < 100.0]\n",
    "    unique_models = set(d[\"model\"] for d in filtered)\n",
    "    unique_hosts = set(d[\"hostname\"] for d in filtered)\n",
    "\n",
    "    return f\"\"\"üìä GPU Utilization Stats (threshold: {threshold}%):\n",
    "\n",
    "üîç Total GPUs: {total}\n",
    "üìà Average Utilization: {avg_util:.2f}%\n",
    "üî¥ Fully Utilized (>=99%): {len(maxed)}\n",
    "üü¢ Idle (<1%): {len(idle)}\n",
    "‚öôÔ∏è Moderate (1-70%): {len(moderate)}\n",
    "üíª Unique Hosts: {len(unique_hosts)}\n",
    "üß† Unique Models: {len(unique_models)}\n",
    "üßÆ Available (<100%): {len(available)}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NRPModel:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.tools = []\n",
    "\n",
    "    def bind_tools(self, tools):\n",
    "        self.tools = tools\n",
    "        return self\n",
    "\n",
    "    def _convert_tool_to_openai_format(self, tool):\n",
    "        \"\"\"Convert LangChain tool to OpenAI tool format\"\"\"\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": tool.name,\n",
    "                \"description\": tool.description,\n",
    "                \"parameters\": tool.args_schema.model_json_schema() if tool.args_schema else {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {},\n",
    "                    \"required\": []\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def invoke(self, messages):\n",
    "        # Convert messages to proper format\n",
    "        formatted_messages = []\n",
    "        for msg in messages:\n",
    "            if hasattr(msg, 'content'):\n",
    "                if msg.__class__.__name__ == \"SystemMessage\":\n",
    "                    formatted_messages.append({\"role\": \"system\", \"content\": msg.content})\n",
    "                elif msg.__class__.__name__ == \"HumanMessage\":\n",
    "                    formatted_messages.append({\"role\": \"user\", \"content\": msg.content})\n",
    "                elif msg.__class__.__name__ == \"AIMessage\":\n",
    "                    formatted_messages.append({\"role\": \"assistant\", \"content\": msg.content})\n",
    "                elif msg.__class__.__name__ == \"ToolMessage\":\n",
    "                    # Truncate tool message content if too long\n",
    "                    content = str(msg.content)\n",
    "                    if len(content) > 2000:\n",
    "                        content = content[:2000] + \"\\n[Content truncated...]\"\n",
    "                    formatted_messages.append({\n",
    "                        \"role\": \"tool\", \n",
    "                        \"content\": content,\n",
    "                        \"tool_call_id\": getattr(msg, 'tool_call_id', 'unknown')\n",
    "                    })\n",
    "            else:\n",
    "                formatted_messages.append(msg)\n",
    "\n",
    "        # Convert tools to OpenAI format\n",
    "        openai_tools = None\n",
    "        if self.tools:\n",
    "            openai_tools = [self._convert_tool_to_openai_format(t) for t in self.tools]\n",
    "\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gemma3\",\n",
    "                temperature=0,\n",
    "                messages=formatted_messages,\n",
    "                tool_choice=\"auto\" if openai_tools else None,\n",
    "                tools=openai_tools,\n",
    "            )\n",
    "\n",
    "            choice = response.choices[0].message\n",
    "\n",
    "            tool_calls = []\n",
    "            if hasattr(choice, \"tool_calls\") and choice.tool_calls:\n",
    "                for t in choice.tool_calls:\n",
    "                    args = t.function.arguments\n",
    "                    if isinstance(args, str):\n",
    "                        try:\n",
    "                            args = json.loads(args)\n",
    "                        except json.JSONDecodeError:\n",
    "                            args = {}\n",
    "                    \n",
    "                    tool_calls.append({\n",
    "                        \"name\": t.function.name,\n",
    "                        \"args\": args,\n",
    "                        \"id\": t.id\n",
    "                    })\n",
    "\n",
    "            return AIMessage(\n",
    "                content=choice.content or \"\",\n",
    "                tool_calls=tool_calls\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return AIMessage(content=f\"Error calling model: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "llm action\n",
    "\n",
    "third argument is dictionary to map the function \n",
    "\n",
    "\n",
    "adding a regular node\n",
    "\n",
    "langchain runnable to call and invoke the graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, system: str = \"\"):\n",
    "        self.system = system\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "        self.max_iterations = 5  # Prevent infinite loops\n",
    "        self.current_iteration = 0\n",
    "\n",
    "        from langgraph.graph import StateGraph, END\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "\n",
    "        self.raw_graph = graph\n",
    "        self.graph = graph.compile()\n",
    "\n",
    "    def exists_action(self, state: AgentState) -> bool:\n",
    "        \"\"\"Check if the last message has tool calls and we haven't exceeded max iterations\"\"\"\n",
    "        if self.current_iteration >= self.max_iterations:\n",
    "            print(f\"‚ö†Ô∏è Reached max iterations ({self.max_iterations}). Stopping.\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            result = state[\"messages\"][-1]\n",
    "            return (hasattr(result, \"tool_calls\") and \n",
    "                    result.tool_calls is not None and \n",
    "                    len(result.tool_calls) > 0)\n",
    "        except (IndexError, KeyError, AttributeError):\n",
    "            return False\n",
    "\n",
    "    def call_openai(self, state: AgentState) -> dict:\n",
    "        messages = state[\"messages\"]\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {\"messages\": [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState) -> dict:\n",
    "        self.current_iteration += 1\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "        \n",
    "        for t in tool_calls:\n",
    "            tool_name = t[\"name\"]\n",
    "            tool_args = t[\"args\"]\n",
    "            print(f\"üîß Calling tool: {tool_name} with args: {tool_args}\")\n",
    "            \n",
    "            if tool_name not in self.tools:\n",
    "                result = \"‚ùå Tool name not recognized. Available tools: \" + \", \".join(self.tools.keys())\n",
    "            else:\n",
    "                try:\n",
    "                    result = self.tools[tool_name].invoke(tool_args)\n",
    "                    # Ensure result is string and truncate if needed\n",
    "                    result = str(result)\n",
    "                    if len(result) > 3000:\n",
    "                        result = result[:3000] + \"\\n\\n[Output truncated to prevent loops]\"\n",
    "                except Exception as e:\n",
    "                    result = f\"‚ùå Tool error: {str(e)}\"\n",
    "            \n",
    "            results.append(ToolMessage(tool_call_id=t[\"id\"], name=tool_name, content=result))\n",
    "        \n",
    "        print(\"‚úÖ Tool(s) executed. Returning to model.\")\n",
    "        return {\"messages\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Updated system prompt to be more specific\n",
    "system_prompt = \"\"\"You are a Kubernetes monitoring assistant. \n",
    "\n",
    "Use these tools to answer questions:\n",
    "- 'describe_pods_tool': View pod/container info in a namespace\n",
    "- 'namespace_gpu_util_tool': View average GPU utilization per namespace  \n",
    "- 'dcgm_gpu_inspect_tool': View detailed GPU metrics (top 10 results)\n",
    "- 'calculate_dcgm_gpu_stats': Get statistical breakdown of GPU usage\n",
    "\n",
    "IMPORTANT: Only call each tool ONCE per question. Use the tool output to provide a direct answer. Do not repeat tool calls.\"\"\"\n",
    "\n",
    "# Create agent with updated tools\n",
    "model = NRPModel(client)\n",
    "tools = [describe_pods_tool, namespace_gpu_util_tool, dcgm_gpu_inspect_tool, calculate_dcgm_gpu_stats]\n",
    "abot = Agent(model=model, tools=tools, system=system_prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset iteration counter before each use\n",
    "def ask_agent(question):\n",
    "    abot.current_iteration = 0  # Reset counter\n",
    "    messages = [HumanMessage(content=question)]\n",
    "    response = abot.graph.invoke({\"messages\": messages})\n",
    "    return response[\"messages\"][-1].content\n",
    "\n",
    "# Test cases\n",
    "print(\"=== Test 1: List pods ===\")\n",
    "print(ask_agent(\"List pods in gsoc namespace\"))\n",
    "\n",
    "print(\"\\n=== Test 2: GPU usage by namespace ===\")  \n",
    "print(ask_agent(\"Show me GPU usage across namespaces\"))\n",
    "\n",
    "print(\"\\n=== Test 3: GPU statistics ===\")\n",
    "print(ask_agent(\"Give me overall GPU statistics for the cluster\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex A100 analysis queries you can try:\n",
    "\n",
    "# 1. Comprehensive A100 analysis\n",
    "query1 = \"\"\"\n",
    "Analyze all modelName=\"NVIDIA A100 80GB PCIe\" I want to know:\n",
    "- How many A100s are available vs fully utilized\n",
    "- Which namespaces are using A100s the most\n",
    "- Show me the top A100s by utilization with their host details\n",
    "- Give me overall statistics for A100s specifically\n",
    "\"\"\"\n",
    "\n",
    "# 2. A100 availability analysis\n",
    "query2 = \"\"\"\n",
    "I need to deploy a new workload that requires A100 GPUs. Can you:\n",
    "- Find all idle or low-utilization A100s (under 10% usage)\n",
    "- Show me which hosts have available A100s\n",
    "- Tell me which namespaces have the most A100 capacity available\n",
    "\"\"\"\n",
    "\n",
    "# 3. A100 performance comparison\n",
    "query3 = \"\"\"\n",
    "Compare A100 usage patterns across different namespaces:\n",
    "- Which namespace is using A100s most efficiently\n",
    "- Are there any A100s that are consistently underutilized\n",
    "- Show me the distribution of A100 utilization levels\n",
    "\"\"\"\n",
    "\n",
    "# 4. A100 resource optimization\n",
    "query4 = \"\"\"\n",
    "Help me optimize A100 resource allocation:\n",
    "- Find A100s with less than 50% utilization that could be reallocated\n",
    "- Identify hosts with mixed A100 utilization (some high, some low on same host)\n",
    "- Show me the overall A100 efficiency across the cluster\n",
    "\"\"\"\n",
    "\n",
    "# 5. Specific A100 investigation\n",
    "query5 = \"\"\"\n",
    "I'm investigating A100 performance issues. Please:\n",
    "- Show me all A100s with utilization above 95%\n",
    "- Identify any A100s that might be stuck or problematic (0% utilization)\n",
    "- Give me detailed host and pod information for the most utilized A100s\n",
    "\"\"\"\n",
    "\n",
    "# Test one of these complex queries\n",
    "print(\"Testing complex A100 analysis query...\")\n",
    "response = ask_agent(query1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(abot.graph.get_graph().draw_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
